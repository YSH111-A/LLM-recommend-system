{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf8c5738-6b74-4919-8fc8-6e48935b9783",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HAMI-core Msg(6108:140666242594624:libvgpu.c:836)]: Initializing.....\n",
      "[HAMI-core Warn(6108:140666242594624:multiprocess_memory_limit.c:592)]: Kick dead proc 5562\n",
      "[HAMI-core Warn(6108:140666242594624:multiprocess_memory_limit.c:592)]: Kick dead proc 5658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/usr/bin/python3.12\n",
      "2.7.1+cu126 12.6\n"
     ]
    }
   ],
   "source": [
    "import sys, torch\n",
    "import pandas as pd \n",
    "print(sys.executable)\n",
    "print(torch.__version__, torch.version.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d57d1cf-6f71-40bd-9dc2-ede545060bff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: http://pip.58dns.org/simple\n",
      "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (0.34.3)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (3.15.4)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2024.6.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (6.0.1)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (4.14.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub) (1.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub) (2024.6.2)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager, possibly rendering your system unusable. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv. Use the --root-user-action option if you know what you are doing and want to suppress this warning.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install huggingface-hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23861b40-08c0-4d21-b1f5-dedd63391c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture #‰∏çÊòæÁ§∫ÂÆâË£ÖËøáÁ®ã\n",
    "!pip install unsloth\n",
    "# Also get the latest nightly Unsloth!\n",
    "# !pip uninstall unsloth -y && pip install --upgrade --no-cache-dir --no-deps git+https://github.com/unslothai/unsloth.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdf35b10-00e9-4418-b496-984390d64fb5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# from unsloth import FastLanguageModel\n",
    "# import torch\n",
    "# max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "# dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "# load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# # 4bit pre quantized models we support for 4x faster downloading + no OOMs.\n",
    "# fourbit_models = [\n",
    "#     \"unsloth/mistral-7b-v0.3-bnb-4bit\",      # New Mistral v3 2x faster!\n",
    "#     \"unsloth/mistral-7b-instruct-v0.3-bnb-4bit\",\n",
    "#     \"unsloth/llama-3-8b-bnb-4bit\",           # Llama-3 15 trillion tokens model 2x faster!\n",
    "#     \"unsloth/llama-3-8b-Instruct-bnb-4bit\",\n",
    "#     \"unsloth/llama-3-70b-bnb-4bit\",\n",
    "#     \"unsloth/Phi-3-mini-4k-instruct\",        # Phi-3 2x faster!\n",
    "#     \"unsloth/Phi-3-medium-4k-instruct\",\n",
    "#     \"unsloth/mistral-7b-bnb-4bit\",\n",
    "#     \"unsloth/gemma-7b-bnb-4bit\",             # Gemma 2.2x faster!\n",
    "# ] # More models at https://huggingface.co/unsloth\n",
    "\n",
    "# model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "#     model_name = \"unsloth/Llama-3.2-3B-Instruct-bnb-4bit\",\n",
    "#     max_seq_length = max_seq_length,\n",
    "#     dtype = dtype,\n",
    "#     load_in_4bit = load_in_4bit,\n",
    "#     # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e234fb-bfe4-4182-a2d7-fd221c899b1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HAMI-core Msg(6108:140666242594624:libvgpu.c:852)]: Initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[HAMI-core Msg(6206:140219002754880:libvgpu.c:836)]: Initializing.....\n",
      "[HAMI-core Msg(6206:140219002754880:libvgpu.c:852)]: Initialized\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: OpenAI failed to import - ignoring for now.\n",
      "ü¶• Unsloth Zoo will now patch everything to make training faster!\n",
      "Standard import failed for UnslothGKDTrainer: No module named 'UnslothGKDTrainer'. Using tempfile instead!\n",
      "==((====))==  Unsloth 2025.8.1: Fast Llama patching. Transformers: 4.55.0.\n",
      "   \\\\   /|    NVIDIA GeForce RTX 4090. Num GPUs = 1. Max memory: 23.25 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.1+cu126. CUDA: 8.9. CUDA Toolkit: 12.6. Triton: 3.3.1\n",
      "\\        /    Bfloat16 = TRUE. FA [Xformers = 0.0.31.post1. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048\n",
    "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "# Êú¨Âú∞Ê®°ÂûãÁõÆÂΩïË∑ØÂæÑ\n",
    "local_model_path = \"/code/ysh/finetuning/data/models/llama-3-8b-bnb-4bit\"\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name=local_model_path,  # <-- ‰ΩøÁî®Êú¨Âú∞Ë∑ØÂæÑ\n",
    "    max_seq_length=max_seq_length,\n",
    "    dtype=dtype,\n",
    "    load_in_4bit=load_in_4bit,\n",
    ")\n",
    "print(\"Ê®°ÂûãÂíåÂàÜËØçÂô®Â∑≤‰ªéÊú¨Âú∞Ë∑ØÂæÑÊàêÂäüÂä†ËΩΩ„ÄÇ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d0a271-a603-4737-b9dc-e67bdc2588b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c80d6b-a7c8-48b9-bf4f-1a8e83c9a5d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###‰ªéËøôÈáåÂºÄÂßãÂáÜÂ§áÊï∞ÊçÆÈõÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4148e2ee-5c49-4ee2-a2c4-23a3821cdee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8181cc17-7aa6-4b3e-b5d9-72a4b734660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"parquet\",data_files='./data/alpaca-gpt4/train.parquet', split = \"train\")\n",
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaec6e8-55ef-4112-a421-952193f2642d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26944a05-0bfe-4afa-a9e3-c52d912425c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_parquet('./data/alpaca-gpt4/train.parquet')\n",
    "df = pd.read_parquet('data/finetuning_data.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86547fe2-66e4-4dad-852d-3393c60e33d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9156299-24bd-4a20-b0ff-78da0c9db633",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e84a5e-ca97-4a3f-bd44-882d46419716",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ÂøÖÈ°ªÂè™Êúâ‰∏§Âàó‚Äî‚Äî‰∏Ä‰∏™ instruction ÂàóÂíå‰∏Ä‰∏™ output Âàó„ÄÇ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36345e9f-4b95-45db-8e02-c06646a73c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import to_sharegpt\n",
    "dataset = to_sharegpt(\n",
    "    dataset,\n",
    "    merged_prompt = \"{instruction}[[\\nYour input is:\\n{input}]]\",\n",
    "    output_column_name = \"output\",\n",
    "    conversation_extension = 3, # Select more to handle longer conversations\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7b74aa-4f41-4e02-8e24-43ec3c4d9898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import standardize_sharegpt\n",
    "dataset = standardize_sharegpt(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113a1484-db02-43a3-b78b-00e1c92604a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "##promptÊ®°Áâà"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd53e3a-f0ed-455e-99b8-32641a24fd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Alpaca Ê†ºÂºè\n",
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21479f10-9e0d-4b84-a9d2-ab0ab6714714",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Llama-3 ÁöÑÊèêÁ§∫Ê†ºÂºèÔºåÂøÖÈ°ª‰ΩøÁî® instruct ËÄå‰∏çÊòØ base \n",
    "chat_template = \"\"\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\n",
    "\n",
    "{SYSTEM}<|eot_id|><|start_header_id|>user<|end_header_id|>\n",
    "\n",
    "{INPUT}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\n",
    "\n",
    "{OUTPUT}<|eot_id|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e2a021d-f561-4b87-8190-531a50471dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ChatML Ê†ºÂºè\n",
    "chat_template = \"\"\"<|im_start|>system\n",
    "{SYSTEM}<|im_end|>\n",
    "<|im_start|>user\n",
    "{INPUT}<|im_end|>\n",
    "<|im_start|>assistant\n",
    "{OUTPUT}<|im_end|>\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e28173-bc4d-4043-b838-5f4df0ad52a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "##ÊúÄÁªà‰ΩøÁî®openaiÊ®°ÁâàÔºå‰∏ÄÈóÆ‰∏ÄÁ≠îÊ†ºÂºè\n",
    "chat_template = \"\"\"Below are some instructions that describe some tasks. Write responses that appropriately complete each request.\n",
    "\n",
    "### Instruction:\n",
    "{INPUT}\n",
    "\n",
    "### Response:\n",
    "{OUTPUT}\"\"\"\n",
    "\n",
    "from unsloth import apply_chat_template\n",
    "dataset = apply_chat_template(\n",
    "    dataset,\n",
    "    tokenizer = tokenizer,\n",
    "    chat_template = chat_template,\n",
    "    # default_system_message = \"You are a helpful assistant\", << [OPTIONAL]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764935b0-004c-41eb-b324-ef8bcbf23975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        max_steps = 60,\n",
    "        # num_train_epochs = 1, # For longer training runs!\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\", # Use this for WandB etc\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4af1c224-d598-41f6-ab57-d73440dd0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a60cc63-3869-4b79-9cd0-5f53d9c0f088",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36332712-e7c6-4b3d-b69e-f9e4a7b5a6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "508f33f5-ed7a-4399-a856-5fb40aa7246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "messages = [                    # Change below!\n",
    "    {\"role\": \"user\", \"content\": \"Filter 5 items that the user may be interested in from candidate items based on the user's personal profile.+UserID: 124, UserProfile: UserID:124 | Gender:M | Age:56 | Occupation:7 | Zip:91356 | RatedMovies:902:4;1544:3;1343:4;3101:4;3107:4;2302:4;527:4;1650:5;2858:3;457:3;3418:5;1358:5;3078:5;1693:4;678:5;531:4;2912:4;1213:4 | FavoriteGenres:Action|Adventure|Children's|Comedy|Crime|Drama|Romance|Sci-Fi|Thriller|War, CandidateItems: 1094:Drama|Romance|War;34:Children's|Comedy|Drama;1179:Crime|Drama|Film-Noir;3125:Drama;3298:Drama;503:Drama;1653:Drama|Sci-Fi|Thriller;1520:Romance;930:Film-Noir|Romance|Thriller;2821:Adventure|Drama;3167:Drama;2153:Action|Adventure;904:Mystery|Thriller;1950:Drama|Mystery;1047:Action|Thriller;1342:Horror;1821:Comedy|Romance;1477:Romance;2692:Action|Crime|Romance;3857:Thriller;2010:Sci-Fi;940:Action|Adventure;2167:Action|Adventure|Horror;3351:Horror;1910:Action|Comedy|Crime;734:Comedy;3894:Drama;618:Comedy|Romance;3747:Drama;2008:Crime|Drama|Film-Noir;429:Comedy;735:Comedy|Horror;1947:Musical|Romance;3262:Drama|Mystery;3674:Adventure|Children's;2799:Comedy;1942:Drama;2884:Comedy|Romance;2174:Comedy|Fantasy;672:Drama;1178:Drama|War;581:Documentary;3796:Romance|Thriller;166:Comedy|Drama;3357:Drama|Romance;2130:Crime|Drama|Romance;2072:Comedy;333:Comedy;424:Drama;690:Romance\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e53df6-7b04-4f4d-bc1b-246b00d9ec27",
   "metadata": {},
   "outputs": [],
   "source": [
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "messages = [                         # Change below!\n",
    "    {\"role\": \"user\",      \"content\": \"Filter 5 items that the user may be interested in from candidate items based on the user's personal profile.+UserID: 124, UserProfile: UserID:124 | Gender:M | Age:56 | Occupation:7 | Zip:91356 | RatedMovies:902:4;1544:3;1343:4;3101:4;3107:4;2302:4;527:4;1650:5;2858:3;457:3;3418:5;1358:5;3078:5;1693:4;678:5;531:4;2912:4;1213:4 | FavoriteGenres:Action|Adventure|Children's|Comedy|Crime|Drama|Romance|Sci-Fi|Thriller|War, CandidateItems: 1094:Drama|Romance|War;34:Children's|Comedy|Drama;1179:Crime|Drama|Film-Noir;3125:Drama;3298:Drama;503:Drama;1653:Drama|Sci-Fi|Thriller;1520:Romance;930:Film-Noir|Romance|Thriller;2821:Adventure|Drama;3167:Drama;2153:Action|Adventure;904:Mystery|Thriller;1950:Drama|Mystery;1047:Action|Thriller;1342:Horror;1821:Comedy|Romance;1477:Romance;2692:Action|Crime|Romance;3857:Thriller;2010:Sci-Fi;940:Action|Adventure;2167:Action|Adventure|Horror;3351:Horror;1910:Action|Comedy|Crime;734:Comedy;3894:Drama;618:Comedy|Romance;3747:Drama;2008:Crime|Drama|Film-Noir;429:Comedy;735:Comedy|Horror;1947:Musical|Romance;3262:Drama|Mystery;3674:Adventure|Children's;2799:Comedy;1942:Drama;2884:Comedy|Romance;2174:Comedy|Fantasy;672:Drama;1178:Drama|War;581:Documentary;3796:Romance|Thriller;166:Comedy|Drama;3357:Drama|Romance;2130:Crime|Drama|Romance;2072:Comedy;333:Comedy;424:Drama;690:Romance\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"interested items: 1094:Drama|Romance|War;34:Children's|Comedy|Drama;1179:Crime|Drama|Film-Noir;3125:Drama;3298:Drama\"},\n",
    "    {\"role\": \"user\",      \"content\": \"Filter 5 items that the user may be interested in from candidate items based on the user's personal profile.+UserID: 433, UserProfile: UserID:433 | Gender:M | Age:50 | Occupation:6 | Zip:55115 | RatedMovies:527:4;1096:5;21:4;3072:3;2736:3;3421:4;2858:4;2289:3;1148:4;1294:4;3543:5;1394:5;1136:3;1230:5;1304:5;1276:5;3210:5;1288:5;3751:4;1965:4;1223:4;377:3;3614:3;471:3;1393:3;25:2;708:3;361:5;356:4;788:2;11:3;1777:3;339:5;539:5;1569:4;2671:1 | FavoriteGenres:Action|Animation|Children's|Comedy|Drama|Fantasy|Musical|Romance|Sci-Fi|Thriller|War|Western, CandidateItems: 804:Comedy|Romance;3004:Comedy|Romance;3:Comedy|Romance;1353:Comedy|Romance;3705:Action|Adventure|Romance|Thriller;2652:Horror;1572:Drama;3190:Adventure|Sci-Fi;2794:Comedy;1231:Drama;2166:Drama|Romance;793:Drama;3540:Romance|Thriller;2581:Comedy|Romance;998:Action|Crime;544:Action;2593:Comedy;310:Comedy;2428:Horror|Sci-Fi;1029:Animation|Children's|Musical;1981:Horror;1228:Drama;1381:Comedy|Musical|Romance;2204:Thriller;352:Comedy;2081:Animation|Children's|Comedy|Musical|Romance;3615:Animation|Children's;2100:Comedy|Fantasy|Romance;1644:Horror|Mystery|Thriller;417:Comedy|Romance;1255:Comedy|Horror;704:Action|Adventure;494:Action|Thriller;658:Drama;1345:Horror;1824:Comedy|Thriller;1784:Comedy|Drama;1322:Horror;1845:Comedy|Thriller;1797:Documentary;2862:Drama;3689:Comedy;3358:Comedy|Romance;3919:Horror;853:Drama;2815:Action|War;415:Comedy|Thriller;2921:Western;5:Comedy;1221:Action|Crime|Drama\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a913db20-57ef-4063-8c0e-b2eb755d0ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3ac0e-10f0-44a6-8852-153a0179a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "##‰øùÂ≠ò„ÄÅÂä†ËΩΩÂæÆË∞ÉÊ®°Âûã\n",
    "# Ëøô‰ªÖ‰øùÂ≠ò‰∫Ü LoRA ÈÄÇÈÖçÂô®ÔºåÂπ∂Êú™‰øùÂ≠òÊï¥‰∏™Ê®°Âûã„ÄÇË¶Å‰øùÂ≠ò‰∏∫ 16 ‰ΩçÊàñ GGUFÔºåËØ∑Áî®‰∏ãÈù¢ÁöÑ\n",
    "model.save_pretrained(\"outputs/lora_model\") # Local saving\n",
    "tokenizer.save_pretrained(\"outputs/lora_model\")\n",
    "# model.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving\n",
    "# tokenizer.push_to_hub(\"your_name/lora_model\", token = \"...\") # Online saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f82f1e4d-983a-442b-ae46-29783ce99e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Â¶ÇÊûúÊÉ≥Âä†ËΩΩÂàöÂàö‰øùÂ≠òÁöÑ LoRA ÈÄÇÈÖçÂô®‰ª•ËøõË°åÊé®ÁêÜÔºåËØ∑Â∞Ü False Êõ¥Êîπ‰∏∫ True\n",
    "if True:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"outputs/lora_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "pass\n",
    "\n",
    "messages = [                    # Change below!\n",
    "    {\"role\": \"user\", \"content\": \"Filter 5 items that the user may be interested in from candidate items based on the user's personal profile.+UserID: 433, UserProfile: UserID:433 | Gender:M | Age:50 | Occupation:6 | Zip:55115 | RatedMovies:527:4;1096:5;21:4;3072:3;2736:3;3421:4;2858:4;2289:3;1148:4;1294:4;3543:5;1394:5;1136:3;1230:5;1304:5;1276:5;3210:5;1288:5;3751:4;1965:4;1223:4;377:3;3614:3;471:3;1393:3;25:2;708:3;361:5;356:4;788:2;11:3;1777:3;339:5;539:5;1569:4;2671:1 | FavoriteGenres:Action|Animation|Children's|Comedy|Drama|Fantasy|Musical|Romance|Sci-Fi|Thriller|War|Western, CandidateItems: 804:Comedy|Romance;3004:Comedy|Romance;3:Comedy|Romance;1353:Comedy|Romance;3705:Action|Adventure|Romance|Thriller;2652:Horror;1572:Drama;3190:Adventure|Sci-Fi;2794:Comedy;1231:Drama;2166:Drama|Romance;793:Drama;3540:Romance|Thriller;2581:Comedy|Romance;998:Action|Crime;544:Action;2593:Comedy;310:Comedy;2428:Horror|Sci-Fi;1029:Animation|Children's|Musical;1981:Horror;1228:Drama;1381:Comedy|Musical|Romance;2204:Thriller;352:Comedy;2081:Animation|Children's|Comedy|Musical|Romance;3615:Animation|Children's;2100:Comedy|Fantasy|Romance;1644:Horror|Mystery|Thriller;417:Comedy|Romance;1255:Comedy|Horror;704:Action|Adventure;494:Action|Thriller;658:Drama;1345:Horror;1824:Comedy|Thriller;1784:Comedy|Drama;1322:Horror;1845:Comedy|Thriller;1797:Documentary;2862:Drama;3689:Comedy;3358:Comedy|Romance;3919:Horror;853:Drama;2815:Action|War;415:Comedy|Thriller;2921:Western;5:Comedy;1221:Action|Crime|Drama\"},\n",
    "]\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    add_generation_prompt = True,\n",
    "    return_tensors = \"pt\",\n",
    ").to(\"cuda\")\n",
    "\n",
    "from transformers import TextStreamer\n",
    "text_streamer = TextStreamer(tokenizer, skip_prompt = True)\n",
    "_ = model.generate(input_ids, streamer = text_streamer, max_new_tokens = 128, pad_token_id = tokenizer.eos_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246414e7-57af-4312-b3c8-04d1319b70fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
